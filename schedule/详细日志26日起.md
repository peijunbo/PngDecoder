# 9月26日

##### 1、决定用roberts算子进行边缘检测。看不懂矩阵什么意思，上网查找后找到一种可能的公式[边缘检测 Roberts算子 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/266361551)

##### 2、反复研究[数字图像处理:边缘检测(Edge detection) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/59640437)。发现简单的算子都差不多，随便选了一个。写出代码后发现与原图像差距不大，再次查阅文档意识到还有梯度图像、非极大值抑制等等。

##### 3、捋一下思路。横向用sobel滤波后在纵向以sobel滤波。遇到一个问题，以owntest.png测试时发现所有纯白像素都被填上了颜色。花了几十分钟对各个点的数据反复print，发现graylist中已经遍历过的数据都发生了改变，上网搜索后意识到是自己基本功不过关。。。尝试将一个列表的值赋给另一个列表时不能用`list1 = list2`这样两个列表指向的地址会是一个地址，改动一个另一个也就跟着变了。。。

##### 4、修改了之后测试成功，不过因为采用的滤波方法过于简单，输出的效果一般。

##### 5、下载opencv库，然而出现了意料之外的问题。在pycharm中始终显示没有cv2模块，也没有代码补全功能。但是写出程序照样可以正常运行，花了近好几个小时上网找，终于找到了解决方法。。。[spyder下，Python3中import cv2时，显示没有“cv2”模块_学学学玩玩玩的博客-CSDN博客](https://blog.csdn.net/qq_30727951/article/details/107976235)。然而过了一会儿又没有代码补全了。再次上网查找，终于有人提到cv2文件夹的路径要求为全英文。于是移动cv2文件夹，成功显示提示。

##### 6、正式开始使用opencv

##### 7、报错，说CRC值错误，说明还是要计算CRC值，上网了解到zlib库就有计算crc32的函数。

##### 8、编写程序，处理图片生成视频。距离成功差最后一步

# 9月27日

##### 1、将处理并产生视频用函数实现，了解os库的`remove()`方法来删除处理过程中产生的图片。完成task8

##### 2、尝试直接将图像格式转为灰度图从而避免对rgb三个列表的处理以提升运行速度。

##### 3、遇到了意料之外的事情，在读取灰度图时发现idat中的第一个像素点的灰度值与打开PS查看的灰度值不同，然而滤波器方法却完全符合。于是我在PS中尝试将第一个像素点的灰度值进行从0至255的遍历，试图找到问题所在。然而发现一件神奇的事情。在PS中，灰度值并不能取到从0至255所有数，如不能取到3、5、7、8...再仔细研究，发现每次PS的灰度值发生跳跃时，程序读取到的灰度值才会加1，猜测问题就出在这里，导致程序读取到的灰度值一般低于PS显示的灰度值。

##### 4、不过至少知道了灰度图中idat的格式，编写程序尝试自己创建灰度图。

# 9月28日

##### 1、写出相应的程序，实现向灰度图的转换。

##### 2、测试后发现PS读取到的第一个像素点灰度值依旧与程序写入的不同。不清楚是PS的原因还是灰度值本身有着某种特殊的对应方法。不过程序确实能正常运行。

##### 3、上网了解到QQ截图也可以查看RGB。于是用QQ截图功能查看灰度图的RGB。首先用windows照片查看器打开再用QQ识别RGB，发现与程序读取到的相同，此时用PS打开同一张灰度图，发现PS显示的灰度值要大。猜测是PS为了使灰度图更好看而强行更改了灰度值的显示。

##### 4、从PS测试.png中可以明显看到PS确实对灰度图进行了处理。

##### 5、测试灰度转换后的效率

| 处理对象 | 处理方式     | 原方法     | 转为灰度图         |
| -------- | ------------ | ---------- | ------------------ |
| test1    | changeedge() | 5.027187   | 3.6544759          |
| test1    | changeedge() | 5.0428013  | 3.6404322000000002 |
| test1    | changegray() | 2.6705469  | 2.2804187999999996 |
| test1    | changegray() | 2.6653742  | 2.2763293          |
| test2    | changegray() | 23.4268171 | 21.0424114         |
| test2    | changegray() | 23.3476318 | 21.6529538         |
| test2    | changeedge() | 38.0338662 | 29.303929099999998 |
| test2    | changeedge() | 38.5094934 | 29.709483199999998 |

​	实践证明更换方法后确实是快了尤其加快了在对灰度图做其他处理的速度。而且经过查看，用原方法产生的test2边缘图大小为8mb多，而直接转化为灰度图的方法大小6mb多。而产生的灰度图大小接近。总体来说新方法确实好。而且还看到在运行时间的增长与循环次数的增长不是简单的线性关系，因此尝试减少循环，用其他方式代替循环。

# 9月30日

##### 1、学习使用ffmpeg，尝试将音频与视频分离后再合并。

##### 2、成功的合成出视频。不过可能是与之前用的原视频不同，这次产生的视频有点糊。

##### 3、将ffmpeg的指令写进程序中，网上了解到`os.system()`就可以实现运行命令。

# 10月1日

##### 1、收到新的任务，先花了1个多小时上网查找，观看了许多视频，了解了大致方法。

##### 2、挑选其中一个教程开始操作[阿里云服务器ECS新手搭建网站视频教程（详细版）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV12T4y1N7T9/?spm_id_from=333.788.recommend_more_video.2)。操作完后发现并没解决问题，不过中途下载了宝塔面板使得后续步骤轻松了许多

##### 3、上传文件，运行。发现无法从外部访问，即使在阿里云里设置了开发10086端口也不行。过了很久，发现宝塔面板里未开放10086端口。不知道该以哪个为准，但在宝塔里开放后可以从外界访问了。

##### 4、上网学习screen来实现程序的后台运行。成功在断开SSH后访问到网站。

##### 5、了解第三个任务，查到端口映射这个概念。加上之前看教程了解到不加端口号默认为80端口，意识到只需要将80端口导向到10086端口即可解决问题。

# 10月2日

##### 1、上网学习端口映射，成功实现不加端口号访问10086端口。

##### 2、查看别人png解码器的代码，对比一下立刻知道的自己的程序慢在何处。因为为了便于过程中的调试以及之后调用的方便，我将读取、解析图片的部分以类的初始化实现，因此在执行特定任务时会做出很多与该任务无关的操作。比如处理test1时我也做了对tEXt等数据块的读取，而他们则针对一个任务，只处理相应数据块。还有我为了过程中方便理解，对每个bytes变量都转换成了10进制数存储起来，而其实单单考虑处理一个图像是不需要这一步的，这步只是方便了写程序的人对图片内容的理解。正因为这一步，导致在对PNG类的处理时，要更改就必须对bytes和10进制两个列表同时更改，又要进行多次的类型转换，进一步拖长的运行时间。总而言之，我的代码在调用时很方便，更改时也更加容易，不过因此运行起来就慢了很多。

# 10月5日

##### 1、最后一次测试程序，修改一些小细节。

